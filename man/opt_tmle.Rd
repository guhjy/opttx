% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/opt_tmle.R
\name{opt_tmle}
\alias{opt_tmle}
\alias{plot.opt_tmle}
\alias{print.opt_tmle}
\title{opt_tmle}
\usage{
opt_tmle(data, Wnodes = grep("^W", names(data), value = T), Anode = "A",
  Ynode = "Y", Vnodes = Wnodes, stratifyAY = TRUE,
  Q_library = c("SL.glm", "SL.glmem", "SL.glmnet", "SL.step.forward",
  "SL.gam", "SL.rpart", "SL.rpartPrune", "SL.mean"), g_library = c("SL.glm",
  "SL.glmnet", "SL.step.forward", "SL.gam", "SL.rpart", "SL.rpartPrune",
  "SL.mean"), blip_library = c("SL.glm", "SL.glmnet", "SL.step.forward",
  "SL.gam", "SL.rpart", "SL.rpartPrune", "SL.mean"), blip_type = c("QbV.mse",
  "cl.surlog"), maximize = T, verbose = 1, parallel = F)

\method{print}{opt_tmle}(obj)

\method{plot}{opt_tmle}(obj)
}
\arguments{
\item{data}{data.frame containing the relevant variable}

\item{Wnodes,}{vector of column names indicating covariates}

\item{Anode,}{column name of treatment}

\item{Ynode,}{column name of outcome}

\item{Vnodes,}{vector of column names to base the treatment on}

\item{stratifyAY,}{logical: should we stratify the cross-validation based on (A,Y) pairs}

\item{Q_library,}{vector of SuperLearner learners for the fit of E(Y|A,W)}

\item{g_library,}{vector of SuperLearner learners for the fit of P(A|W)}

\item{blip_library,}{vector of SuperLearner learners for the fit of E(Y_1-Y_0|V)}

\item{blip_type,}{character indicating type of blip, default is 'Qbv.mse'}

\item{maximize,}{logical: should we try to maximize the outcome (because it's a positive outcome)}

\item{verbose,}{integer that controls the verbosity of the output (higher is more verbose)}

\item{parallel,}{logical: should foreach parallelization be used?}
}
\description{
Estimation of the Optimal Treatment rule using Super Learner and mean performance using CV-TMLE
To avoid nesting cross-validation, it uses split-specfic estimates of Q and g to estimate the rule, and
'split-specific' estimates of the rule in CV-TMLE to estimate mean performance
}
\examples{
library(opttx)
Qbar0 <- function(A, W) {
    W1 <- W[, 1]
    W2 <- W[, 2]
    W3 <- W[, 3]
    W4 <- W[, 4]
    Qbar <- ifelse(W4 > 0, plogis(1 - W1^2 + 3 * W2 + A * (5 * W3^2 - 4.45)), plogis(-0.5 - W3 + 2 * W1 * W2 + A * (3 * 
        abs(W2) - 1.5)))
    return(Qbar)
}

g0 <- function(W) {
    W1 <- W[, 1]
    W2 <- W[, 2]
    W3 <- W[, 3]
    W4 <- W[, 4]
    
    # rep(0.5, nrow(W))
    plogis(0.25 * W1 - 0.1 * W2)
}

gen_data <- function(n = 1000, p = 4) {
    W <- matrix(rnorm(n * p), nrow = n)
    colnames(W) <- paste("W", seq_len(p), sep = "")
    A <- rbinom(n, 1, g0(W))
    u <- runif(n)
    Y <- as.numeric(u < Qbar0(A, W))
    Y0 <- as.numeric(u < Qbar0(0, W))
    Y1 <- as.numeric(u < Qbar0(1, W))
    d0 <- as.numeric(Qbar0(1, W) > Qbar0(0, W))
    Yd0 <- as.numeric(u < Qbar0(d0, W))
    data.frame(W, A, Y, Y0, Y1, Yd0, d0, blip = Qbar0(1, W) - Qbar0(0, W))
}

data <- gen_data(1000, 5)

system.time({
    result <- opt_tmle(data, blip_type = "cl.surlog")
})

# perf of true blip approx=0.595
mean(pmax(Qbar0(0, data[, result$nodes$Wnodes]), Qbar0(1, data[, result$nodes$Wnodes])))

# confirm D1 isn't too crazy quantile(extract_vals(result$folds, result$split_preds)$D1)
# quantile(cv_predict_original(result$fits$blip_fit))

print(result)
plot(result)

vim <- tx_vim(result)
ggplot(vim, aes(y = node, x = risk_full_fraction, color = model)) + geom_point() + theme_bw() + xlab("VIM")

library(reshape2)
long <- melt(vim, id = c("node", "model"))
ggplot(long, aes(y = node, x = value, color = model)) + geom_point() + facet_wrap(~variable, scales = "free") + theme_bw() 
}
\seealso{
\code{\link{assign_treatment}}
}

